PROJECT_DIR="$(pwd)"
CONFIG_PATH="$PROJECT_DIR/verl/examples/sglang_multiturn/config"

export CUDA_VISIBLE_DEVICES=0

python3 -m verl.trainer.main_ppo \
  --config-path="$CONFIG_PATH" \
  --config-name='wordle_w_interaction' \
  algorithm.adv_estimator=grpo \
  data.train_files=/tmp/wordle_data/train_wordle_dataset.parquet \
  data.val_files=/tmp/wordle_data/train_wordle_dataset.parquet \
  data.return_multi_modal_inputs=false \
  data.train_batch_size=8 \
  data.max_prompt_length=128 \
  data.max_response_length=4096 \
  data.return_raw_chat=true \
  actor_rollout_ref.model.path=loganbolton/qwen-wordle-finetuned \
  actor_rollout_ref.rollout.name=sglang \
  actor_rollout_ref.rollout.multi_turn.enable=True \
  +actor_rollout_ref.rollout.max_steps=7 \
  ++actor_rollout_ref.rollout.n=32 \
  +actor_rollout_ref.rollout.multi_turn.tool_config_path=verl/examples/sglang_multiturn/config/tool_config/wordle_tool_config.yaml \
  actor_rollout_ref.rollout.multi_turn.interaction_config_path="verl/examples/sglang_multiturn/config/interaction_config/wordle_interaction_config.yaml" \
  ++actor_rollout_ref.rollout.multi_turn.tokenization_sanity_check_mode="disable" \
  actor_rollout_ref.rollout.tensor_model_parallel_size=1 \
  actor_rollout_ref.rollout.gpu_memory_utilization=0.6 \
  actor_rollout_ref.actor.optim.lr=6e-6 \
  actor_rollout_ref.actor.ppo_mini_batch_size=4 \
  actor_rollout_ref.actor.ppo_micro_batch_size=4 \
  actor_rollout_ref.actor.use_kl_loss=true \
  actor_rollout_ref.actor.kl_loss_coef=0.02 \
  actor_rollout_ref.ref.log_prob_micro_batch_size=4 \
  actor_rollout_ref.rollout.log_prob_micro_batch_size=4 \
  actor_rollout_ref.actor.strategy="fsdp2" \
  +custom_reward_function.path=$PROJECT_DIR/verl/examples/sglang_multiturn/reward_fn/wordle_reward.py \
  ++custom_reward_function.name=wordle_reward \
  reward_model.enable=false \
  reward_model.reward_manager=wordle \
  ++actor_rollout_ref.model.enable_activation_offload=true \
  ++actor_rollout_ref.ref.entropy_from_logits_with_chunking=true \
  ++actor_rollout_ref.actor.entropy_checkpointing=false \
  trainer.logger="['console','wandb']" \
  trainer.project_name=verl_wordle \
  trainer.experiment_name=wordle-qwen2.5-0.5b \
  trainer.n_gpus_per_node=1 \
  trainer.nnodes=1 \
  trainer.total_epochs=10 \
  trainer.val_before_train=false \
  trainer.log_val_generations=1 \
  trainer.test_freq=5 \
  trainer.save_freq=5 \
  trainer.resume_mode=disable \