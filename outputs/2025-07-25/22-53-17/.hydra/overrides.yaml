- algorithm.adv_estimator=grpo
- data.train_files=/tmp/wordle_data/train_wordle_dataset.parquet
- data.val_files=/tmp/wordle_data/val_wordle_dataset.parquet
- data.return_multi_modal_inputs=false
- data.train_batch_size=2
- data.max_prompt_length=512
- data.max_response_length=128
- data.return_raw_chat=true
- actor_rollout_ref.model.path=Qwen/Qwen3-1.7B
- actor_rollout_ref.rollout.name=sglang
- actor_rollout_ref.rollout.multi_turn.enable=True
- +actor_rollout_ref.rollout.max_steps=7
- ++actor_rollout_ref.rollout.n=8
- +actor_rollout_ref.rollout.multi_turn.tool_config_path=verl/examples/sglang_multiturn/config/tool_config/wordle_tool_config.yaml
- actor_rollout_ref.rollout.multi_turn.interaction_config_path=verl/examples/sglang_multiturn/config/interaction_config/wordle_interaction_config.yaml
- actor_rollout_ref.rollout.tensor_model_parallel_size=1
- actor_rollout_ref.rollout.gpu_memory_utilization=0.4
- actor_rollout_ref.actor.optim.lr=1e-6
- actor_rollout_ref.actor.ppo_mini_batch_size=2
- actor_rollout_ref.actor.ppo_micro_batch_size=2
- actor_rollout_ref.actor.use_kl_loss=true
- actor_rollout_ref.actor.kl_loss_coef=0.001
- actor_rollout_ref.ref.log_prob_micro_batch_size=2
- actor_rollout_ref.rollout.log_prob_micro_batch_size=2
- actor_rollout_ref.actor.strategy=fsdp2
- +custom_reward_function.path=/workspace/verl/examples/sglang_multiturn/reward_fn/wordle_reward.py
- ++custom_reward_function.name=wordle_reward
- reward_model.enable=false
- reward_model.reward_manager=wordle
- ++actor_rollout_ref.model.enable_activation_offload=true
- ++actor_rollout_ref.ref.entropy_from_logits_with_chunking=true
- ++actor_rollout_ref.actor.entropy_checkpointing=false
- trainer.logger=['console','wandb']
- trainer.project_name=verl_wordle
- trainer.experiment_name=wordle-qwen2.5-0.5b
- trainer.n_gpus_per_node=2
- trainer.nnodes=1
- trainer.total_epochs=50
- trainer.val_before_train=false
- trainer.log_val_generations=1
- trainer.test_freq=4
- trainer.save_freq=-1
